# packages/framework:
#import numpy as np
#import pandas as pd
#from datetime import timedelta


# TEST ALGORITMO:

print("BUILDING THE ALGORITHM on the first 6 unique timestamps:")
print("\n")

#1) Extract the first 6 timestamps of trainset observations in order to iterate over them:
trainset_timestamps_six = df6[df6['Type'] == 'TRAINSET']['Time'].unique()[:6]
print(f"len unique timestamps (check that they are 6): {len(trainset_timestamps_six)}")
print("\n")

#2) Initialize the dictionary and create the vector of delta seconds that identify duplicates of trainset observations:
trainset_duplicates_six = {}
Delta = []
for i in range(4):
    time_window_i = timedelta(seconds=i)
    Delta.append(time_window_i)
print(f"Delta seconds list to indentify trainset obs: {Delta}")

#3) Building the algorithm:
for time in trainset_timestamps_six:
    str_ts = pd.to_datetime(str(time))
    for delta in Delta:
        timestamp = str_ts+delta
        if timestamp in df6["Time"].values:
            key_time = str_ts.strftime('%Y-%m-%d %H:%M:%S')
            id_i = df6.index[df6['Time'] == timestamp].tolist()
            print("\n")
            print(f"key_time: {key_time}")
            print(f"id_i: {id_i}")
            if key_time in trainset_duplicates_six.keys():
                    trainset_duplicates_six[key_time].extend(id_i)
                    print(f"obs in existing {key_time}: {trainset_duplicates_six[key_time]}")
            else:
                    new_key = []
                    new_key.extend(id_i)
                    trainset_duplicates_six[key_time] = new_key
                    print(f"obs in new {key_time}: {trainset_duplicates_six[key_time]}")

'''
#4) Check the results:
print("\n")
print("key_time: 2021-01-14 11:16:51")
print(df6.iloc[28080:28086])
print("\n")
print("key_time: 2021-01-14 12:08:37")
print(df6.iloc[28115:28118])
print("\n")
print("key_time: 2021-01-14 12:18:14")
print(df6.iloc[28124:28130])
print("\n")
print("key_time: 2021-01-14 13:10:02")
print(df6.iloc[28140:28142])
print("\n")
print("key_time: 2021-01-14 13:10:15")
print(df6.iloc[28141:28143])
print("\n")
print("key_time: 2021-01-14 14:14:40")
print(df6.iloc[28165:28168])
'''

# 5) Check the dictionary:
print("\n")
print(f"Dictionary from the first 6 unique timestamps: \n{trainset_duplicates_six}")
print("\n")



#----------------------------------------------------------------------------------------------------------------------#



# ASSUMPTION 3 SECONDS RANGE:

print("APPLYING THE ALGORITHM TOTALLY starting from the assumption of 3 seconds range:")
print("\n")

#1) Identify duplicated obs generated by each trainset obs (range of 3 sec) --> define a map where the key is the timestamp of the trainset obs and the values are the obs with the same timestamp, timestamp+1, timestamp+2, timestamp+3 :

trainset_timestamps = df6[df6['Type'] == 'TRAINSET']['Time'].unique()
print(f"len unique timestamps (all):  {len(trainset_timestamps)}")  # =39733
print("\n")

trainset_duplicates = {}
Delta = []
for i in range(4):
    time_window_i = timedelta(seconds=i)
    Delta.append(time_window_i)
print(f"Delta seconds list to indentify trainset obs: {Delta}")
print("\n")

for time in trainset_timestamps:
    str_ts = pd.to_datetime(str(time))
    for delta in Delta:
        timestamp = str_ts+delta
        if timestamp in df6["Time"].values:
            key_time = str_ts.strftime('%Y-%m-%d %H:%M:%S')
            id_i = df6.index[df6['Time'] == timestamp].tolist()
            if key_time in trainset_duplicates.keys():
                    trainset_duplicates[key_time].extend(id_i)
            else:
                    new_key = []
                    new_key.extend(id_i)
                    trainset_duplicates[key_time] = new_key

# check:
print(f"Total number of keys (timestamps) in the dictionary: {len(trainset_duplicates)}")                   # =39733 (top))
print(f"Total number of values in the dictionary: {sum(len(v) for v in trainset_duplicates.values())}")     # =121777 (azz)
print("\n")


#2) Check no ripetizione trainset duplicati (no più chiavi con stesso timestamp perchè ci sono duplicati di trainset):

duplicate_timestamps = trainset_timestamp_counts[trainset_timestamp_counts > 1].index
# find 5 duplicate timestamps:
print(f"First 10 duplicate timestamps: {duplicate_timestamps[:10]}")
print("\n")

dupl_timestamp_five = duplicate_timestamps[:10]
dupl_timestamp_five_str = []
for i in dupl_timestamp_five:
    a = pd.to_datetime(str(i))
    b = a.strftime('%Y-%m-%d %H:%M:%S')
    dupl_timestamp_five_str.append(b)

print(f"First 10 duplicate timestamps: {dupl_timestamp_five_str}")
print("\n")

print("trainset duplicats with those timestamps:")
for i in dupl_timestamp_five_str:
    print("\n")
    print(f"obs in {i}: {trainset_duplicates[i]}")

'''
print("\n")
print("key_time: 2022-10-16 14:50:50")
print(df6.iloc[625980:625995])
'''



#3) Check increasing delta by 1:
print("\n")
print("DEEPER CHECK: does the algorithm correctly work? Check the increase when moving from 0 to 1 seconds")

trainset_duplicates_delta0 = {}
Delta0 = []
for i in range(1):
    time_window_i = timedelta(seconds=i)
    Delta0.append(time_window_i)
print("\n")
print(f"Delta list: {Delta0}")
print("\n")

for time in trainset_timestamps:
    str_ts = pd.to_datetime(str(time))
    for delta in Delta0:
        timestamp = str_ts+delta
        if timestamp in df6["Time"].values:
            key_time = str_ts.strftime('%Y-%m-%d %H:%M:%S')
            id_i = df6.index[df6['Time'] == timestamp].tolist()
            if key_time in trainset_duplicates_delta0.keys():
                    trainset_duplicates_delta0[key_time].extend(id_i)
            else:
                    new_key = []
                    new_key.extend(id_i)
                    trainset_duplicates_delta0[key_time] = new_key

# check:
print(f"Total number of keys (timestamps) in the dictionary: {len(trainset_duplicates_delta0)}")                   # =39733
print(f"Total number of values in the dictionary: {sum(len(v) for v in trainset_duplicates_delta0.values())}")     # =54941



trainset_duplicates_delta1 = {}
Delta1 = []
for i in range(2):
    time_window_i = timedelta(seconds=i)
    Delta1.append(time_window_i)
print("\n")
print(f"Delta list: {Delta0}")
print("\n")

for time in trainset_timestamps:
    str_ts = pd.to_datetime(str(time))
    for delta in Delta1:
        timestamp = str_ts+delta
        if timestamp in df6["Time"].values:
            key_time = str_ts.strftime('%Y-%m-%d %H:%M:%S')
            id_i = df6.index[df6['Time'] == timestamp].tolist()
            if key_time in trainset_duplicates_delta1.keys():
                    trainset_duplicates_delta1[key_time].extend(id_i)
            else:
                    new_key = []
                    new_key.extend(id_i)
                    trainset_duplicates_delta1[key_time] = new_key

# check:
print(f"Total number of keys (timestamps) in the dictionary: {len(trainset_duplicates_delta1)}")                   # =39733
print(f"Total number of values in the dictionary: {sum(len(v) for v in trainset_duplicates_delta1.values())}")     # =96010 (top)




#4) Compute the time difference between each pair of last duplicated obs-new alert --> define a map where the keys are the same as the previous map (mappa_id) and the value is the delta between the last element of the key of mappa_id and the following observation in the dataset, this for each timestamp (trainset):

Dict_DiffTime = {}
for key_i in trainset_duplicates.keys():
    obs = trainset_duplicates[key_i]
    lastelement = obs[-1]
    if (lastelement + 1 < len(df6)):
        lastelement_time = df6.loc[lastelement,"Time"]
        next_element_time = df6.loc[lastelement+1,"Time"]
        Dict_DiffTime[key_i] = next_element_time-lastelement_time

# check:
print("\n")
print(f"Total number of keys (timestamps) in the dictionary of DiffTime: {len(Dict_DiffTime)}")     # 39732 --> top! (l'ultima oss è scartata altrimenti l'algoritmo non funziona perchè l'ultima oss è trainset e non esiste niente oltre per calcolare la differenza)
#print(f"Entire DiffTime: \n{Dict_DiffTime}")




#5) Check if the range of 3 second is reasonable --> does a new observation (new alert) occur within 1,2,3,5,7,10 seconds?:

print("Is the 3 sec range reasonable?:")
range_sec = [1,2,3,5,7,10]
for i in range_sec:
    count = 0
    for ele in Dict_DiffTime.keys():
        if(Dict_DiffTime[ele]<= timedelta(seconds=i)):
            count+=1
    print(f"{count} observations occur within {i} seconds")

# results:
#2095 observations occur within 1 seconds
#2674 observations occur within 2 seconds
#3553 observations occur within 3 seconds
#5933 observations occur within 5 seconds
#8305 observations occur within 7 seconds
#11537 observations occur within 10 seconds



#----------------------------------------------------------------------------------------------------------------------#


'''
# ASSUMPTION 4 SEC RANGE:

trainset_timestamps = df6[df6['Type'] == 'TRAINSET']['Time'].unique()
print("len timestamps:", len(trainset_timestamps))

trainset_duplicates = {}
Delta = []
for i in range(5):
    time_window_i = timedelta(seconds=i)
    Delta.append(time_window_i)
print("Delta list:", Delta)

for time in trainset_timestamps:
    str_ts = pd.to_datetime(str(time))
    for delta in Delta:
        timestamp = str_ts+delta
        if timestamp in df6["Time"].values:
            key_time = str_ts.strftime('%Y-%m-%d %H:%M:%S')
            id_i = df6.index[df6['Time'] == timestamp].tolist()
            if key_time in trainset_duplicates.keys():
                    trainset_duplicates[key_time].extend(id_i)
            else:
                    new_key = []
                    new_key.extend(id_i)
                    trainset_duplicates[key_time] = new_key

# check:
print(f"Total number of keys (timestamps) in the dictionary: {len(trainset_duplicates)}")                   # 24185
print(f"Total number of values in the dictionary: {sum(len(v) for v in trainset_duplicates.values())}")     # 76160
Dict_DiffTime = {}
for key_i in trainset_duplicates.keys():
    obs = trainset_duplicates[key_i]
    lastelement = obs[-1]
    lastelement_time = df6.loc[lastelement,"Time"]
    next_element_time = df6.loc[lastelement+1,"Time"]
    Dict_DiffTime[key_i] = next_element_time-lastelement_time

# check:
print(f"Total number of keys (timestamps) in the dictionary: {len(Dict_DiffTime)}")

Dict_DiffTime
range_sec = [1,2,3]
for i in range_sec:
    count = 0
    for ele in Dict_DiffTime.keys():
        if(Dict_DiffTime[ele]<= timedelta(seconds=i)):
            count+=1
    print(f"{count} observations occur within {i} seconds")
'''